---
title: "Maximum Likelihood"
author: "Mehman Ismayilli, PhD, FHEA"
date: " 12 May 2025"
institute: "University of Oxford"
format: 
    revealjs:
      theme: serif
      css: styles.css
      slide-number: true
      transition: slide
      logo: images/oxford_logo.png  # optional
      chalkboard: true  # optional
      html-math-method: katex
incremental: true
---

## Recap

<div style="background-color:#f0f8ff; padding: 0.5em; border-radius: 2px;">
  <h3><strong> What We've Done So Far:</strong></h3>
  <ul>
    <li>Learned key ideas in <strong>probability theory</strong>, assuming we know the full distribution (pmf/pdf):
      <ul>
        <li>How to compute <strong>moments</strong> of a random variable</li>
        <li >How to find <strong>cdfs</strong> and <strong>interval probabilities</strong></li>
        <li>How to define and verify <strong>independence</strong></li>
      </ul>
  <li>‚úîÔ∏è <strong>Assumption</strong>: We know the distribution and its parameters.</li>
  </ul>
</div>

### Quiz
:::{.nonincremental}
- Do we always know probability density/mass functions (pdf/pmf) or  the underlying model parameters of any data set?
:::

:::{.columns}
:::{.column}
Join at: **slido.com** - #1952 424 or with QR code:
:::

:::{.column}
<img src="images/Slido.png" width="160px">
:::

:::

---

## Quiz 

<iframe src="https://wall.sli.do/event/t2T4tg9DnCt13kU84bq334/?section=b86c34f6-25c2-49a8-b38a-41ea706a5d1d" height="100%" width="100%" frameBorder="0" style="min-height: 560px;" allow="clipboard-write" title="Slido"></iframe>

---

## From Knowing the Distribution to Learning from Data

<div class="fragment" style="background-color:#f2f2f2; padding: 0.5em; border-radius: 5px; margin-top: 0.5em;">
  <h3><strong>Now, Let‚Äôs Get Real</strong></h3>
  <ul>
    <li style="color: red;"><strong>In practice, we rarely know the actual distribution or its parameters!</strong></li>
    <li >What we <strong>do</strong> have is <strong>data</strong> ‚Äî observations from the unknown distribution.</li>
    <li >Using this data, we can:
      <ul>
        <li><strong>Infer</strong> characteristics of the distribution</li>
        <li ><strong>Estimate</strong> unknown quantities (like parameters or moments)</li>
      </ul>
  <li>üîç <strong>Key idea</strong>: Use data to learn what we don‚Äôt know.</li>
  </ul>
</div>

### Methods of Estimation{.fragment}

- Frequentist methods & Bayesian estimators - *No single method is uniformly superior*.

- Today's focus: <u>Maximum Likelihood Method</u>
  - A powerful and widely used *frequentist* estimation technique

---


## Intended Learning Outcomes (ILOs)

:::{.nonincremental}
- By the end of this session, you will:
  - üí° Understand the concept of **Maximum Likelihood Estimation (MLE)**.
  - üìâ Analyse the role of the **log-likelihood function** in MLE.
  - üì† Compute the **MLE** for simple cases (e.g., IID data).
:::

### Familiarity with the topic{.incremental}

- How familiar are you with the Maximum Likelihood?
  - Join at: **slido.com** - #1952 424 or with QR code:
  - <img src="images/Slido.png" width="160px">

---

## Familiarity with the topic (quiz outcome)

<iframe src="https://wall.sli.do/event/t2T4tg9DnCt13kU84bq334/?section=b86c34f6-25c2-49a8-b38a-41ea706a5d1d" height="100%" width="100%" frameBorder="0" style="min-height: 560px;" allow="clipboard-write" title="Slido"></iframe>

---


## Interactive Normal Distribution Estimation

A certain random variable has distribution of $N(\mu, \sigma^{2})$ but **not known**  mean and variance parameters.**Estimate the *mean* and *variance*.**

<div style="display: flex; gap: 20px;">
<div style="flex: 1;">
<label for="mu">Mean (Œº):</label>
<input type="range" id="mu" min="0" max="10" step="0.1" value="0" oninput="updatePlot()">
<span id="muVal">5</span>
</div>
<div style="flex: 1;">
<label for="sigma">Standard Deviation (œÉ):</label>
<input type="range" id="sigma" min="0.1" max="5" step="0.1" value="0" oninput="updatePlot()">
<span id="sigmaVal">3</span>
</div>
</div>
<div id="histogram" style="width:100%; height:425px; display:flex; align-items:center; justify-content:center;"></div>
<script src="https://cdn.plot.ly/plotly-2.24.2.min.js"></script>
<script>
// Sample data (same as set.seed(1) in R)
const data = [ 8.25,  3.78,  3.94,  2.85,  6.73,  0.4 ,  8.49,  3.48,  5.64,
        4.5 ,  7.92,  0.88,  4.36,  4.23,  7.27,  2.8 ,  4.66,  3.24,
        5.08,  6.17,  2.8 ,  7.29,  6.8 ,  6.  ,  6.8 ,  3.63,  4.75,
        3.13,  4.46,  6.06,  3.62,  4.21,  3.63,  3.31,  3.66,  4.97,
        2.77,  5.47,  8.32,  6.48,  4.62,  3.22,  3.51,  8.38,  5.1 ,
        3.73,  5.38,  9.2 ,  5.24,  6.23,  5.6 ,  4.3 ,  2.71,  4.3 ,
        4.58,  6.17,  6.68,  6.86,  5.57,  6.77,  3.49,  7.51,  6.03,
        4.4 ,  5.98,  4.85,  7.26,  8.04,  9.37,  2.21,  2.11,  3.99,
        5.32,  6.75,  5.63,  0.96,  4.39,  6.66,  5.46,  6.52,  4.56,
        4.6 ,  5.37,  5.82,  5.4 ,  5.24,  3.66,  5.76,  5.24,  7.26,
        7.4 ,  5.37,  4.25,  3.72,  5.85,  5.15,  4.31,  5.09,  3.76,
        6.4 ,  4.11,  7.45,  5.81,  6.19,  2.81,  5.34,  6.48,  3.09,
        4.47,  5.07,  2.25,  5.63,  6.69,  3.28,  5.7 ,  2.38,  4.92,
        1.77,  7.24,  5.82,  4.95,  3.45,  7.55,  8.93,  1.28,  7.47,
        8.26,  5.68,  2.6 ,  6.73,  4.64,  3.79,  2.54,  6.1 ,  6.59,
        3.75,  6.04,  2.71,  6.6 ,  5.09,  4.63,  4.8 ,  6.74,  6.5 ,
        6.06,  5.28,  5.16,  6.24,  5.46,  6.37,  4.38,  0.13,  7.08,
        9.37,  5.88,  4.8 ,  4.73,  4.76,  5.03,  2.76,  3.97,  3.01,
        5.5 ,  4.41,  5.99,  4.65,  6.97,  5.43,  9.38,  1.21,  3.71,
        6.8 , 10.06,  4.5 ,  5.09,  4.55,  7.66,  4.43,  6.36,  4.36,
        2.45,  5.63,  6.01,  7.59,  4.78,  3.77,  6.13,  5.48,  5.56,
        4.85,  7.32,  5.74,  8.81,  7.22,  6.32,  1.75,  6.2 ,  5.84,
        6.62,  7.09];

function normalDensity(x, mu, sigma) {
  return (1 / (sigma * Math.sqrt(2 * Math.PI))) * Math.exp(-0.5 * Math.pow((x - mu) / sigma, 2));
}

function updatePlot() {
  const mu = parseFloat(document.getElementById('mu').value);
  const sigma = parseFloat(document.getElementById('sigma').value);
  document.getElementById('muVal').innerText = mu;
  document.getElementById('sigmaVal').innerText = sigma;

  const hist = {
    x: data,
    type: 'histogram',
    histnorm: 'probability density',
    name: 'Data',
    marker: {
                    color: 'rgba(0, 33, 71, 0.6)',
                    line: {
                        color: 'rgba(0, 33, 71, 1)',
                        width: 1
                    }
                },
                opacity: 0.7
  };

  const x_vals = [];
  for (let i = 0; i < 100; i++) {
    x_vals.push(1 + i * 0.1);  // from ~1 to 11
  }

  const normal = {
    x: x_vals,
    y: x_vals.map(x => normalDensity(x, mu, sigma)),
    mode: 'lines',
    line: {color: 'red'},
    name: 'Estimated Normal Curve',
    type: 'scatter'
  };

  const logLik = data.reduce((sum, x) =>
    sum + Math.log(normalDensity(x, mu, sigma)), 0).toFixed(2);

  Plotly.newPlot('histogram', [hist, normal], {
    xaxis: {title: 'Value'},
    yaxis: {title: 'Density'}
  });
}

updatePlot();  // Initial render
</script>

- $\hat{\mu} = 5.21$ & $\hat{\sigma} = 1.82$; [Detailed Jupyter Notebook here](https://colab.research.google.com/drive/1RjP9kjG-q3UhCsT4Fn7dpNvm-d_huYxa?usp=sharing) 


---

## Maximum Likelihood Formal Setting

<div class="fragment" style="background-color:#f0f8ff; padding: 0.5em; border-radius: 2px; margin-top: 0em;">

### Data

- For simplicity, assume the variable of interest is *continuously distributed*
  - Underlying discussion applies to both **discrete** and **continuous** random variables

- Observe $n$ data points, $Y_{1}, Y_{2}, \dots, Y_{n}$.

  - Define $\mathbf{Y} = (Y_{1}, Y_{2}, \dots, Y_{n})$.

  - The joint *pdf* of $\mathbf{Y}$ is given by $f(\mathbf{Y}; \theta)$
    - <span style="color: red;">$\theta$ </span> the parameters of this pdf and can be a *vector* containing multiple parameters
</div>


<div class="fragment" style="background-color:#eafce2; padding: 0.5em; border-radius: 2px; margin-top: 0em;">
### Technique

<blockquote class="fragment" style=" margin-top: 0em; color: darkblue">
<strong>  The maximum likelihood method is to find the parameter values of pdf which fit the observed data as closely as possible. </strong>
</blockquote>
</div>
---

## Likelihood function for IID Data

<blockquote class="fragment" style=" margin-top: 0em; color: black; background-color:#f0f8ff">
<strong> When data are independently and identically distributed (IID), the joint likelihood function is simply the product of all marginal PDFs.  </strong>
</blockquote>

- Suppose $Y_{1},\ldots, Y_{n}$ are IID with PDF $f_{i}(y; \theta)$. Then, joint density function is $$f(\mathbf{y}; \theta) = \prod_{i=1}^{n} f_{i}(y_i; \theta).$$

### Log-likelihood{.fragment}
- Let $L (\theta; \mathbf{y}) = f(\mathbf{y}; \theta)$. *Log-Likelihood* function is $l(\theta; \mathbf{y}) \equiv \log L (\theta; \mathbf{y})$

- In practice, one usually maximises the *log-likelihood* function, given by $l(\theta; \mathbf{y}) \equiv \log L (\theta; \mathbf{y})$: $$\hat{\theta} = \arg \max_{\theta}l(\theta; \mathbf{y}) = \textcolor{orange}{ \arg \max_{\theta} \sum^{n}_{i=1} \log f_{i}(y_{i};\theta).}$$
- log is a monotonic transformation, $\log L (\theta; \mathbf{y})$ and $L (\theta; \mathbf{y})$ are maximised at the same $\theta$. 

- When not, the maximum likelihood can still be found using numerical methods. Software tools or numerical tools (e.g. Newton-Raphson iteration).

---

## Conclusion

- The maximum likelihood method requires the econometrician to know (or to be happy to assume to know) the true distribution underlying data.

- Solving the first order conditions yields the likelihood estimator (assuming that the likelihood is (strictly) concave)


### Post-Class Discussion & Feedback{.fragment} 

- Question: **Why might ML method be useful even if the distribution we assume is actually wrong?**

  - [Link to the question](https://padlet.com/ismayillimehman/ml-discussion-board-sau21g08d8fn5sr2)

  - <img src="images/padletQR_code.png" width="200px">

--- 

## Marble Game - Homework

<p style="font-size: 14px;">An urn contains n different colored marbles. Marbles are selected one at a time at random with replacement until one marble has been selected twice. What is your estimate of the number of marbles in the urn?</p>

<p style="font-size: 14px;">[Link to Mathematica Notebook](https://drive.google.com/file/d/10wQV8pYKvCpL0nxF86Pi3O9yO7TS1HDP/view?usp=sharing) </p>

<button onclick="drawMarble()" id="drawBtn">Select a Marble</button>
<button onclick="resetGame()">Reset</button>
<panel id="marbleDisplay"> </panel> 
<panel id="estimatePanel" style="display:none;font-size: 14px;"> </panel> 
<select id="userGuess" onchange="updateLikelihood()" disabled>
  <option value="-">-- Choose your estimate --</option>
</select>
<label style="margin-left: 10px; font-size: 14px;"><input type="checkbox" id="showLikCheckbox" onchange="toggleLikelihood()"> Show Likelihood Function</label>

<div class="likelihood-section"> <div class="likelihood-left">
<strong>Likelihood and MLE Explanation</strong>
<div id="likelihoodDetails" class="likelihood-info"></div>
</div>
<div class="likelihood-right">
<strong>Likelihood Function Visualization</strong>
<canvas id="likelihoodCanvas" width="auto" height="150"></canvas>
</div>
</div>
<style>
    button, select {
      margin: 6px 4px;
      padding: 6px;
      font-size: 12px;
    }
    .marble {
      width: 20px;
      height: 20px;
      border-radius: 40%;
      display: inline-block;
      margin: 2px;
      border: 1px solid #333;
    }
    .panel {
      background: white;
      padding: 5px;
      font-size: 10px
      margin-top: 5px;
      border-radius: 8px;
    }
    .likelihood-info {
      margin-top: 0px;
      font-size: 10px
      padding: 0px;
      background: #fefefe;
      border-radius: 2px;
    }
    .chart-container {
    display: flex;
    align-items: left;
    gap: 10px;
    transform: scale(0.8);
    transform-origin: top left;
    }
    .block{
      font-size: 10px; /* ‚¨ÖÔ∏è Changed from 14px to 16px */
    }
        .likelihood-section {
      display: flex;
      justify-content: space-between;
      gap: 20px;
      margin-top: 10px;
    }

    .likelihood-left, .likelihood-right {
      flex: 1;
      font-size: 14px;
    }

    .likelihood-right canvas {
      width: 100% !important;
      height: auto !important;
    }
  </style>

<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
<script>
let colorList = ['red', 'green', 'blue', 'black', 'cyan', 'magenta', 'yellow', 'brown', 'orange', 'pink', 'purple'];
let trueN, selectedFromUrn, set, marbles = [], seen = new Set(), k = 0;
let chartInstance;

function initializeUrn() {
  trueN = Math.floor(Math.random() * 11) + 5;
  selectedFromUrn = Array.from({length: trueN + 1}, () => Math.floor(Math.random() * trueN));
  set = [];
  for (let i = 0; i < selectedFromUrn.length; i++) {
    let sub = selectedFromUrn.slice(0, i+1);
    if (new Set(sub).size !== sub.length) {
      set = sub;
      break;
    }
  }
  k = 0;
  seen.clear();
  marbles = set.map(i => colorList[i % colorList.length]);
}

function drawMarble() {
  if (k >= marbles.length) return;

  const color = marbles[k];
  
  if (seen.has(color)) {
    // Repeated color found, stop drawing
    k++; // include the repeated marble in the display
    displayMarbles();
    showEstimatePrompt();
    enableUserGuess();
    document.getElementById("drawBtn").disabled = true; // Disable further drawing
    return;
  }

  seen.add(color);
  k++;
  displayMarbles();
}

function displayMarbles() {
  const container = document.getElementById("marbleDisplay");
  container.innerHTML = marbles.slice(0, k).map(color => `<div class="marble" style="background:${color}"></div>`).join('');
}

function showEstimatePrompt() {
  const panel = document.getElementById("estimatePanel");
  panel.style.display = 'block';
  panel.innerHTML = `<p>Based on seeing <strong>${k - 1}</strong> different marbles before a repeat, estimate the number of marbles in the urn:</p>`;
}

function enableUserGuess() {
  const select = document.getElementById("userGuess");
  for (let i = 1; i <= 100; i++) {
    let option = document.createElement("option");
    option.value = i;
    option.text = i;
    select.appendChild(option);
  }
  select.disabled = false;
}

function lik(x) {
  if (k < 2 || x <= k - 2) return 0;
  let product = 1;
  for (let i = 1; i <= k - 2; i++) {
    product *= (x - i);
  }
  return product * (k - 1) / Math.pow(x, k - 1);
}

function MLE() {
  if (k === 2) return 1;
  if (k === 3) return 2;
  let maxVal = -Infinity, mle = k-1;
  for (let i = k-1; i <= 8 * k; i++) {
    const val = lik(i);
    if (val > maxVal) {
      maxVal = val;
      mle = i;
    }
  }
  return mle;
}

function updateLikelihood() {
  const j = parseInt(document.getElementById("userGuess").value);
  if (isNaN(j) || j === '-') return;
  const prob = lik(j).toFixed(6);
  const details = document.getElementById("likelihoodDetails");
  details.innerHTML = `<strong>Likelihood Function Result:</strong><br>
    P(k = ${k-1} | n = ${j}) = <strong>${prob}</strong>`;
  if (document.getElementById("showLikCheckbox").checked) drawLikelihood();
}

function drawLikelihood() {
  const ctx = document.getElementById("likelihoodCanvas").getContext('2d');
  const labels = [], data = [];
  let maxLik = -Infinity, mle = k-1;
  for (let i = k-1; i <= 8 * k; i++) {
    const value = lik(i);
    labels.push(i);
    data.push(value);
    if (value > maxLik) {
      maxLik = value;
      mle = i;
    }
  }
  if (chartInstance) chartInstance.destroy();
  chartInstance = new Chart(ctx, {
    type: 'line',
    data: {
      labels: labels,
      datasets: [
        {
          label: 'Likelihood P(k | n)',
          data: data,
          fill: true,
          borderColor: 'blue',
          backgroundColor: 'rgba(0, 0, 255, 0.1)',
          tension: 0.3,
          pointRadius: 2
        },
        {
          label: 'MLE',
          data: labels.map(n => n === mle ? lik(n) : null),
          borderColor: 'red',
          backgroundColor: 'red',
          pointRadius: 6,
          type: 'scatter',
          showLine: false
        }
      ]
    },
    options: {
      plugins: {
        title: {
          display: true,
          text: 'Likelihood Function vs. Number of Marbles (n)'
        },
        tooltip: {
          callbacks: {
            label: function(context) {
              return `n = ${context.label}, Likelihood = ${context.raw.toFixed(6)}`;
            }
          }
        },
        legend: {
          display: true
        }
      },
      scales: {
        x: {
          title: {
            display: true,
            text: 'Number of Marbles (n)'
          }
        },
        y: {
          title: {
            display: true,
            text: 'Likelihood'
          }
        }
      }
    }
  });
  document.getElementById("likelihoodCanvas").style.display = "block";
  const details = document.getElementById("likelihoodDetails");
  details.innerHTML += `<br><br><strong>Maximum Likelihood Estimate:</strong><br>
    The MLE is the value of <strong>n = ${mle}</strong> where the likelihood function reaches its maximum.<br>
    Likelihood at MLE = <strong>${lik(mle).toFixed(6)}</strong>`;
}

function toggleLikelihood() {
  if (document.getElementById("showLikCheckbox").checked) drawLikelihood();
  else document.getElementById("likelihoodCanvas").style.display = "none";
}

function resetGame() {
  initializeUrn();
  document.getElementById("marbleDisplay").innerHTML = "";
  document.getElementById("estimatePanel").innerHTML = "";
  document.getElementById("estimatePanel").style.display = "none";
  document.getElementById("userGuess").innerHTML = '<option value="-">-- Choose your estimate --</option>';
  document.getElementById("userGuess").disabled = true;
  document.getElementById("likelihoodCanvas").style.display = "none";
  document.getElementById("likelihoodDetails").innerHTML = "";
  if (chartInstance) chartInstance.destroy();
  k = 0;
  seen.clear();
  document.getElementById("drawBtn").disabled = false; // ‚úÖ Re-enable draw button
}

initializeUrn();
</script>

### Homework{.fragment}

- <p style="font-size: 14px;"> Find the pdf of this distribution.</p>

- <p style="font-size: 14px;"> Derive the log-likelihood function and estimate $n$ when the number of distinct marbles before a repeat, $k$ is 4. Post your detailed solutions to Blackboard discussions for feedback.</p>
