## Recap <div style="background-color:#f0f8ff; padding: 0.5em; border-radius: 2px;"> <h3><strong> What We've Done So Far:</strong></h3> <ul> <li>Learned key ideas in <strong>probability theory</strong>, assuming we know the full distribution (pmf/pdf): <ul> <li>How to compute <strong>moments</strong> of a random variable</li> <li>How to find <strong>cdfs</strong> and <strong>interval probabilities</strong></li> <li>How to define and verify <strong>independence</strong></li> </ul> <li>‚úîÔ∏è <strong>Assumption</strong>: We know the distribution and its parameters.</li> </ul> </div> ### Quiz :::{.nonincremental} - Do we always know probability density/mass functions (pdf/pmf) or the underlying model parameters of any data set? ::: :::{.columns} :::{.column} Join at: **slido.com** - #1952 424 or with QR code: ::: :::{.column} <img src="images/Slido.png" width="160px"> ::: ::: --- ## Quiz <iframe src="https://wall.sli.do/event/t2T4tg9DnCt13kU84bq334/?section=b86c34f6-25c2-49a8-b38a-41ea706a5d1d" height="100%" width="100%" frameBorder="0" style="min-height: 560px;" allow="clipboard-write" title="Slido"></iframe> --- ## From Knowing the Distribution to Learning from Data <div class="fragment" style="background-color:#f2f2f2; padding: 0.5em; border-radius: 5px; margin-top: 0.5em;"> <h3><strong>Now, Let‚Äôs Get Real</strong></h3> <ul> <li style="color: red;"><strong>In practice, we rarely know the actual distribution or its parameters!</strong></li> <li>What we <strong>do</strong> have is <strong>data</strong> ‚Äî observations from the unknown distribution.</li> <li>Using this data, we can: <ul> <li><strong>Infer</strong> characteristics of the distribution</li> <li><strong>Estimate</strong> unknown quantities (like parameters or moments)</li> </ul> <li>üîç <strong>Key idea</strong>: Use data to learn what we don‚Äôt know.</li> </ul> </div> ### Methods of Estimation{.fragment} - Frequentist methods & Bayesian estimators - *No single method is uniformly superior*. - Today's focus: <u>Maximum Likelihood Method</u> - A powerful and widely used *frequentist* estimation technique --- ## Intended Learning Outcomes (ILOs) :::{.nonincremental} - By the end of this session, you will: - üí° Understand the concept of **Maximum Likelihood Estimation (MLE)**. - üìâ Analyse the role of the **log-likelihood function** in MLE. - üì† Compute the **MLE** for simple cases (e.g., IID data). ::: ### Familiarity with the topic{.incremental} - How familiar are you with the Maximum Likelihood? - Join at: **slido.com** - #1952 424 or with QR code: - <img src="images/Slido.png" width="160px"> --- ## Familiarity with the topic (quiz outcome) <iframe src="https://wall.sli.do/event/t2T4tg9DnCt13kU84bq334/?section=b86c34f6-25c2-49a8-b38a-41ea706a5d1d" height="100%" width="100%" frameBorder="0" style="min-height: 560px;" allow="clipboard-write" title="Slido"></iframe> --- ## Interactive Normal Distribution Estimation A certain random variable has distribution of $N(\mu, \sigma^{2})$ but **not known** mean and variance parameters.**Estimate the *mean* and *variance*.** <div style="display: flex; gap: 20px;"> <div style="flex: 1;"> <label for="mu">Mean (Œº):</label> <input type="range" id="mu" min="0" max="10" step="0.1" value="0" oninput="updatePlot()"> <span id="muVal">5</span> </div> <div style="flex: 1;"> <label for="sigma">Standard Deviation (œÉ):</label> <input type="range" id="sigma" min="0.1" max="5" step="0.1" value="0" oninput="updatePlot()"> <span id="sigmaVal">3</span> </div> </div> <div id="histogram" style="width:100%; height:425px; display:flex; align-items:center; justify-content:center;"></div> <script src="https://cdn.plot.ly/plotly-2.24.2.min.js"></script> <script>function normalDensity(t,e,a){return 1/(a*Math.sqrt(2*Math.PI))*Math.exp(-.5*Math.pow((t-e)/a,2))}function updatePlot(){const t=parseFloat(document.getElementById("mu").value),e=parseFloat(document.getElementById("sigma").value);document.getElementById("muVal").innerText=t,document.getElementById("sigmaVal").innerText=e;const a={x:data,type:"histogram",histnorm:"probability density",name:"Data",marker:{color:"rgba(0, 33, 71, 0.6)",line:{color:"rgba(0, 33, 71, 1)",width:1}},opacity:.7},n=[];for(let t=0;t<100;t++)n.push(1+.1*t);const o={x:n,y:n.map(a=>normalDensity(a,t,e)),mode:"lines",line:{color:"red"},name:"Estimated Normal Curve",type:"scatter"};data.reduce((a,n)=>a+Math.log(normalDensity(n,t,e)),0).toFixed(2);Plotly.newPlot("histogram",[a,o],{xaxis:{title:"Value"},yaxis:{title:"Density"}})}const data=[8.25,3.78,3.94,2.85,6.73,.4,8.49,3.48,5.64,4.5,7.92,.88,4.36,4.23,7.27,2.8,4.66,3.24,5.08,6.17,2.8,7.29,6.8,6,6.8,3.63,4.75,3.13,4.46,6.06,3.62,4.21,3.63,3.31,3.66,4.97,2.77,5.47,8.32,6.48,4.62,3.22,3.51,8.38,5.1,3.73,5.38,9.2,5.24,6.23,5.6,4.3,2.71,4.3,4.58,6.17,6.68,6.86,5.57,6.77,3.49,7.51,6.03,4.4,5.98,4.85,7.26,8.04,9.37,2.21,2.11,3.99,5.32,6.75,5.63,.96,4.39,6.66,5.46,6.52,4.56,4.6,5.37,5.82,5.4,5.24,3.66,5.76,5.24,7.26,7.4,5.37,4.25,3.72,5.85,5.15,4.31,5.09,3.76,6.4,4.11,7.45,5.81,6.19,2.81,5.34,6.48,3.09,4.47,5.07,2.25,5.63,6.69,3.28,5.7,2.38,4.92,1.77,7.24,5.82,4.95,3.45,7.55,8.93,1.28,7.47,8.26,5.68,2.6,6.73,4.64,3.79,2.54,6.1,6.59,3.75,6.04,2.71,6.6,5.09,4.63,4.8,6.74,6.5,6.06,5.28,5.16,6.24,5.46,6.37,4.38,.13,7.08,9.37,5.88,4.8,4.73,4.76,5.03,2.76,3.97,3.01,5.5,4.41,5.99,4.65,6.97,5.43,9.38,1.21,3.71,6.8,10.06,4.5,5.09,4.55,7.66,4.43,6.36,4.36,2.45,5.63,6.01,7.59,4.78,3.77,6.13,5.48,5.56,4.85,7.32,5.74,8.81,7.22,6.32,1.75,6.2,5.84,6.62,7.09];updatePlot();</script> - $\hat{\mu} = 5.21$ & $\hat{\sigma} = 1.82$; [Detailed Jupyter Notebook here](https://colab.research.google.com/drive/1RjP9kjG-q3UhCsT4Fn7dpNvm-d_huYxa?usp=sharing) --- ## Maximum Likelihood Formal Setting <div class="fragment" style="background-color:#f0f8ff; padding: 0.5em; border-radius: 2px; margin-top: 0em;"> ### Data - For simplicity, assume the variable of interest is *continuously distributed* - Underlying discussion applies to both **discrete** and **continuous** random variables - Observe $n$ data points, $Y_{1}, Y_{2}, \dots, Y_{n}$. - Define $\mathbf{Y} = (Y_{1}, Y_{2}, \dots, Y_{n})$. - The joint *pdf* of $\mathbf{Y}$ is given by $f(\mathbf{Y}; \theta)$ - <span style="color: red;">$\theta$ </span> the parameters of this pdf and can be a *vector* containing multiple parameters </div> <div class="fragment" style="background-color:#eafce2; padding: 0.5em; border-radius: 2px; margin-top: 0em;"> ### Technique <blockquote class="fragment" style=" margin-top: 0em; color: darkblue"> <strong> The maximum likelihood method is to find the parameter values of pdf which fit the observed data as closely as possible. </strong> </blockquote> </div> --- ## Likelihood function for IID Data <blockquote class="fragment" style=" margin-top: 0em; color: black; background-color:#f0f8ff"> <strong> When data are independently and identically distributed (IID), the joint likelihood function is simply the product of all marginal PDFs. </strong> </blockquote> - Suppose $Y_{1},\ldots, Y_{n}$ are IID with PDF $f_{i}(y; \theta)$. Then, joint density function is $$f(\mathbf{y}; \theta) = \prod_{i=1}^{n} f_{i}(y_i; \theta).$$ ### Log-likelihood{.fragment} - Let $L (\theta; \mathbf{y}) = f(\mathbf{y}; \theta)$. *Log-Likelihood* function is $l(\theta; \mathbf{y}) \equiv \log L (\theta; \mathbf{y})$ - In practice, one usually maximises the *log-likelihood* function, given by $l(\theta; \mathbf{y}) \equiv \log L (\theta; \mathbf{y})$: $$\hat{\theta} = \arg \max_{\theta}l(\theta; \mathbf{y}) = \textcolor{orange}{ \arg \max_{\theta} \sum^{n}_{i=1} \log f_{i}(y_{i};\theta).}$$ - log is a monotonic transformation, $\log L (\theta; \mathbf{y})$ and $L (\theta; \mathbf{y})$ are maximised at the same $\theta$. - When not, the maximum likelihood can still be found using numerical methods. Software tools or numerical tools (e.g. Newton-Raphson iteration). --- ## Conclusion - The maximum likelihood method requires the econometrician to know (or to be happy to assume to know) the true distribution underlying data. - Solving the first order conditions yields the likelihood estimator (assuming that the likelihood is (strictly) concave) ### Post-Class Discussion & Feedback{.fragment} - Question: **Why might ML method be useful even if the distribution we assume is actually wrong?** - [Link to the question](https://padlet.com/ismayillimehman/ml-discussion-board-sau21g08d8fn5sr2) - <img src="images/padletQR_code.png" width="200px"> --- ## Marble Game - Homework <p style="font-size: 14px;">An urn contains n different colored marbles. Marbles are selected one at a time at random with replacement until one marble has been selected twice. What is your estimate of the number of marbles in the urn?</p> <p style="font-size: 14px;">[Link to Mathematica Notebook](https://drive.google.com/file/d/10wQV8pYKvCpL0nxF86Pi3O9yO7TS1HDP/view?usp=sharing) </p> <button onclick="drawMarble()" id="drawBtn">Select a Marble</button> <button onclick="resetGame()">Reset</button> <panel id="marbleDisplay"> </panel> <panel id="estimatePanel" style="display:none;font-size: 14px;"> </panel> <select id="userGuess" onchange="updateLikelihood()" disabled> <option value="-">-- Choose your estimate --</option> </select> <label style="margin-left: 10px; font-size: 14px;"><input type="checkbox" id="showLikCheckbox" onchange="toggleLikelihood()"> Show Likelihood Function</label> <div class="likelihood-section"> <div class="likelihood-left"> <strong>Likelihood and MLE Explanation</strong> <div id="likelihoodDetails" class="likelihood-info"></div> </div> <div class="likelihood-right"> <strong>Likelihood Function Visualization</strong> <canvas id="likelihoodCanvas" width="auto" height="150"></canvas> </div> </div> <style>button,select{margin:6px 4px;padding:6px;font-size:12px}.marble{width:20px;height:20px;border-radius:40%;display:inline-block;margin:2px;border:1px solid #333}.panel{background:white;padding:5px;font-size:10px margin-top:5px;border-radius:8px}.likelihood-info{margin-top:0;font-size:10px padding:0;background:#fefefe;border-radius:2px}.chart-container{display:flex;align-items:left;gap:10px;transform:scale(0.8);transform-origin:top left}.block{font-size:10px}.likelihood-section{display:flex;justify-content:space-between;gap:20px;margin-top:10px}.likelihood-left,.likelihood-right{flex:1;font-size:14px}.likelihood-right canvas{width:100%!important;height:auto!important}</style> <script src="https://cdn.jsdelivr.net/npm/chart.js"></script> <script>function initializeUrn(){trueN=Math.floor(11*Math.random())+5,selectedFromUrn=Array.from({length:trueN+1},()=>Math.floor(Math.random()*trueN)),set=[];for(let e=0;e<selectedFromUrn.length;e++){let t=selectedFromUrn.slice(0,e+1);if(new Set(t).size!==t.length){set=t;break}}k=0,seen.clear(),marbles=set.map(e=>colorList[e%colorList.length])}function drawMarble(){if(k>=marbles.length)return;const e=marbles[k];if(seen.has(e))return k++,displayMarbles(),showEstimatePrompt(),enableUserGuess(),void(document.getElementById("drawBtn").disabled=!0);seen.add(e),k++,displayMarbles()}function displayMarbles(){document.getElementById("marbleDisplay").innerHTML=marbles.slice(0,k).map(e=>`<div class="marble" style="background:${e}"></div>`).join("")}function showEstimatePrompt(){const e=document.getElementById("estimatePanel");e.style.display="block",e.innerHTML=`<p>Based on seeing <strong>${k-1}</strong> different marbles before a repeat, estimate the number of marbles in the urn:</p>`}function enableUserGuess(){const e=document.getElementById("userGuess");for(let t=1;t<=100;t++){let n=document.createElement("option");n.value=t,n.text=t,e.appendChild(n)}e.disabled=!1}function lik(e){if(k<2||e<=k-2)return 0;let t=1;for(let n=1;n<=k-2;n++)t*=e-n;return t*(k-1)/Math.pow(e,k-1)}function MLE(){if(2===k)return 1;if(3===k)return 2;let e=-Infinity,t=k-1;for(let n=k-1;n<=8*k;n++){const o=lik(n);o>e&&(e=o,t=n)}return t}function updateLikelihood(){const e=parseInt(document.getElementById("userGuess").value);if(isNaN(e)||"-"===e)return;const t=lik(e).toFixed(6);document.getElementById("likelihoodDetails").innerHTML=`<strong>Likelihood Function Result:</strong><br>\n    P(k = ${k-1} | n = ${e}) = <strong>${t}</strong>`,document.getElementById("showLikCheckbox").checked&&drawLikelihood()}function drawLikelihood(){const e=document.getElementById("likelihoodCanvas").getContext("2d"),t=[],n=[];let o=-Infinity,l=k-1;for(let e=k-1;e<=8*k;e++){const i=lik(e);t.push(e),n.push(i),i>o&&(o=i,l=e)}chartInstance&&chartInstance.destroy(),chartInstance=new Chart(e,{type:"line",data:{labels:t,datasets:[{label:"Likelihood P(k | n)",data:n,fill:!0,borderColor:"blue",backgroundColor:"rgba(0, 0, 255, 0.1)",tension:.3,pointRadius:2},{label:"MLE",data:t.map(e=>e===l?lik(e):null),borderColor:"red",backgroundColor:"red",pointRadius:6,type:"scatter",showLine:!1}]},options:{plugins:{title:{display:!0,text:"Likelihood Function vs. Number of Marbles (n)"},tooltip:{callbacks:{label:function(e){return`n = ${e.label}, Likelihood = ${e.raw.toFixed(6)}`}}},legend:{display:!0}},scales:{x:{title:{display:!0,text:"Number of Marbles (n)"}},y:{title:{display:!0,text:"Likelihood"}}}}}),document.getElementById("likelihoodCanvas").style.display="block",document.getElementById("likelihoodDetails").innerHTML+=`<br><br><strong>Maximum Likelihood Estimate:</strong><br>\n    The MLE is the value of <strong>n = ${l}</strong> where the likelihood function reaches its maximum.<br>\n    Likelihood at MLE = <strong>${lik(l).toFixed(6)}</strong>`}function toggleLikelihood(){document.getElementById("showLikCheckbox").checked?drawLikelihood():document.getElementById("likelihoodCanvas").style.display="none"}function resetGame(){initializeUrn(),document.getElementById("marbleDisplay").innerHTML="",document.getElementById("estimatePanel").innerHTML="",document.getElementById("estimatePanel").style.display="none",document.getElementById("userGuess").innerHTML='<option value="-">-- Choose your estimate --</option>',document.getElementById("userGuess").disabled=!0,document.getElementById("likelihoodCanvas").style.display="none",document.getElementById("likelihoodDetails").innerHTML="",chartInstance&&chartInstance.destroy(),k=0,seen.clear(),document.getElementById("drawBtn").disabled=!1}let trueN,selectedFromUrn,set,chartInstance,colorList=["red","green","blue","black","cyan","magenta","yellow","brown","orange","pink","purple"],marbles=[],seen=new Set,k=0;initializeUrn();</script> ### Homework{.fragment} - <p style="font-size: 14px;"> Find the pdf of this distribution.</p> - <p style="font-size: 14px;"> Derive the log-likelihood function and estimate $n$ when the number of distinct marbles before a repeat, $k$ is 4. Post your detailed solutions to Blackboard discussions for feedback.</p>